{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA/ETL Prototype\n",
    "\n",
    "In this notebook we prototype the data acquisition and cleaning process. First we import all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import rrule\n",
    "import pandas as pd\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset that is acquired is the turbine metadata. This is returned from the API as a JSON object, which we convert to the Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://eersc.usgs.gov/api/uswtdb/v1/turbines?&t_state=in.(WA,OR)&select=t_cap,t_hh,xlong,ylat\")\n",
    "turbine_data = pd.DataFrame(r.json()).dropna()\n",
    "turbine_data[\"xlong\"] = 360. + turbine_data[\"xlong\"]\n",
    "turbine_data.to_csv(\"turbine_metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we download the wind power data from the BPA Balancing Authority API. This file is a CSV file, which we read into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_data = pd.read_csv(\"https://transmission.bpa.gov/Business/Operations/Wind/twndbspt.txt\", skiprows=10, delimiter=\"\\t\")\n",
    "power_data.set_index(power_data.columns[0], inplace=True)\n",
    "power_data.index = pd.to_datetime(power_data.index) + timedelta(hours=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the latitude and longitude ranges of the Pacific Northwest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LON_MIN = 360. - 125.\n",
    "LON_MAX = 360. - 115.\n",
    "LAT_MIN = 40.\n",
    "LAT_MAX = 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we write a function that downloads the weather simulation data from the NOAA API. The wind speed is calculated from the velocity, and the temperate is also extracted. The function downloads data for every hour for a single specified day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vel_data_for_date(date, LON_MIN, LON_MAX, LAT_MIN, LAT_MAX):\n",
    "    date_str = date.strftime(\"%Y%m%d\")\n",
    "    print(\"Downloading weather simulation data for \", date_str)\n",
    "    \n",
    "    vel = []\n",
    "    T = []\n",
    "    \n",
    "    hs_vel = np.array([10, 20, 30, 40, 50, 80, 100])\n",
    "    hs_T = np.array([2, 80, 100])\n",
    "    \n",
    "    for hr_base in [0, 6, 12, 18]:\n",
    "        try:\n",
    "            weather_data_url = \"https://nomads.ncep.noaa.gov/dods/gfs_0p25_1hr/gfs{}/gfs_0p25_1hr_{:02d}z\".format(date_str, hr_base)\n",
    "            weather_data = Dataset(weather_data_url)\n",
    "            hrs = range(6)\n",
    "        except OSError as e:\n",
    "            hr_base -= 6\n",
    "            weather_data_url = \"https://nomads.ncep.noaa.gov/dods/gfs_0p25_1hr/gfs{}/gfs_0p25_1hr_{:02d}z\".format(date_str, hr_base)\n",
    "            weather_data = Dataset(weather_data_url)\n",
    "            hrs = range(6, 12)\n",
    "        \n",
    "        lon = weather_data.variables[\"lon\"][:]\n",
    "        lat = weather_data.variables[\"lat\"][:]\n",
    "\n",
    "        pnw_lat_idx = np.logical_and(LAT_MIN <= lat, lat <= LAT_MAX)\n",
    "        pnw_lon_idx = np.logical_and(LON_MIN <= lon, lon <= LON_MAX)\n",
    "\n",
    "        for hr in hrs:\n",
    "            vel_hr = np.zeros((np.sum(pnw_lat_idx), np.sum(pnw_lon_idx), len(hs_vel)))\n",
    "            for k, h_vel in enumerate(hs_vel):\n",
    "                vel_hr[:,:,k] = np.sqrt(weather_data.variables[\"ugrd{}m\".format(h_vel)][hr,:,:]**2 \\\n",
    "                                      + weather_data.variables[\"vgrd{}m\".format(h_vel)][hr,:,:]**2)[np.ix_(pnw_lat_idx, pnw_lon_idx)]\n",
    "            vel.append(vel_hr)\n",
    "            \n",
    "            T_hr = np.zeros((np.sum(pnw_lat_idx), np.sum(pnw_lon_idx), len(hs_T)))\n",
    "            for k, h_T in enumerate(hs_T):\n",
    "                T_hr[:,:,k] = weather_data.variables[\"tmp{}m\".format(h_T)][hr,:,:][np.ix_(pnw_lat_idx, pnw_lon_idx)]\n",
    "            T.append(T_hr)\n",
    "\n",
    "    return vel, T, lat[pnw_lat_idx], lon[pnw_lon_idx], hs_vel, hs_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we write a function that takes wind data (or temperature data) at a specific time, and interpolates it to the turbine locations using trilinear interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_wind_data(turbine_data, vel, lat, lon, hs):\n",
    "    rgi = RegularGridInterpolator((lat, lon, hs,), vel, method=\"linear\")\n",
    "    turb_locs = turbine_data[[\"ylat\", \"xlong\", \"t_hh\"]].to_numpy()\n",
    "    return rgi(turb_locs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we put it all together into a single loop that downloads data for the past few days, interpolates the weather data to the turbine locations, and then combines the data with the wind power generation data and saves it to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=[\"turb_{}_vel\".format(i) for i in range(len(turbine_data))] + [\"turb_{}_T\".format(i) for i in range(len(turbine_data))])\n",
    "\n",
    "num_days = 4\n",
    "for date_time in rrule.rrule(rrule.DAILY, dtstart=datetime.today().date() - timedelta(days=num_days + 1), until=datetime.today().date()):\n",
    "    vel, T, lat, lon, hs_vel, hs_T = get_vel_data_for_date(date_time, LON_MIN, LON_MAX, LAT_MIN, LAT_MAX)\n",
    "    for hr in range(24):\n",
    "        data.loc[data.shape[0]] = np.hstack((interpolate_wind_data(turbine_data, vel[hr], lat, lon, hs_vel),\n",
    "                                             interpolate_wind_data(turbine_data, T[hr], lat, lon, hs_T)))\n",
    "        \n",
    "data = data.set_index(pd.date_range(datetime.today().date() - timedelta(days=num_days + 1), datetime.today().date() + timedelta(days=1), freq=\"H\", closed=\"left\"))\n",
    "data = data.join(power_data)\n",
    "data.to_csv(\"sample_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the full application, these functions will be rewritten so that the data is properly stored in a database and incrementally updated as it becomes available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
